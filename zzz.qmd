---
title: "수자원공사, 마사회 기사 비교분석"
format: html
author: 언론홍보학과 2019102107 김지후
title-block-style: default
title-block-banner: "#6E6E6E"
date: 2022-10-12
code-fold: true
code-tools: true
---

## 빅카인즈에서 데이터셋을 추출해 두 공사간 비교분석을 실시함

### 1. 필요 패키지 설치

### 2. 각 공사 키워드별 상위단어 분석

### 3. 각 공사 키워드별 긍정, 부정단어 분석


### 1. 필요 패키지 설치


```{r}
#| warning: false

install.packages("readxl",repos = "http://cran.us.r-project.org")
install.packages("tidyverse",repos = "http://cran.us.r-project.org")
install.packages("tidytext",repos = "http://cran.us.r-project.org")
install.packages("kableExtra",repos = "http://cran.us.r-project.org")
install.packages("wordcloud",repos = "http://cran.us.r-project.org")
install.packages("tidylo",repos = "http://cran.us.r-project.org")
install.packages("RcppMeCab",repos = "http://cran.us.r-project.org")

library(tidylo)
library(tidyverse)
library(tidytext)
library(kableExtra)
library(wordcloud)
library(readxl)
```



```{r}
list.files("data/.")

list.files("data/knusenti/KnuSentiLex-master/")

senti_name_v <- list.files("data/knusenti/KnuSentiLex-master/.")[9]

senti_name_v

read_lines(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v)) %>% head(10)

read_lines(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v)) %>% 
  head(10) %>% str_extract("\t|\n| ")

read_tsv(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v)) %>% head(10)
read_tsv(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v), col_names = F) %>% head(10)

senti_dic_df <- read_tsv(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v), col_names = F)

glimpse(senti_dic_df)

senti_dic_df[1-5, ]

senti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)
glimpse(senti_dic_df)

pkg_v <- c("tidyverse", "tidytext","RcppMeCab")

lapply(pkg_v, require, ch = T)

install.packages("stm", dependencies = T,repos = "http://cran.us.r-project.org")

install.packages("gt",repos = "http://cran.us.r-project.org")
```




```
```{r}

m_df <- readxl::read_excel("masahwe.xlsx") %>% 
  select(제목, 본문)

s_df <- readxl::read_excel("수자원공사 2020.01.01~.xlsx") %>% 
  select(제목, 본문)


```


```{r}
m_df2 <- m_df %>% 
  distinct(제목, .keep_all = T) %>% 
  mutate(ID = factor(row_number())) %>% 
  mutate(label = "0") %>%
  unite(제목, 본문, col = "text", sep = " ") %>% 
  mutate(text = str_squish(text))

m_tk <- m_df2 %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = "regex", drop = F) %>%
  count(word, sort = T)

m_tk <- 
m_tk %>% 
  filter(!word %in% c("영천경마공원", "한국마사회", "경마공원", "기자", "마사회","옵티머스","경마","부산경남경마공원","김우남","공기업","문중원","기수","렛츠런파크","부경경마공원","부경","코로나","공공기관","부산동구지사","일까지", "우승")) %>% 
  filter(str_detect(word, "[:alpha:]+")) %>%
  filter(str_length(word) > 1) %>%
  slice_max(n, n = 15) %>% 
  mutate(word = reorder(word, n))

m_tk %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  labs(title = "마사회 단어 총빈도 분석")
```

```{r}
s_df2 <- s_df %>% 
  distinct(제목, .keep_all = T) %>% 
  mutate(ID = factor(row_number())) %>% 
  mutate(label = "0") %>%
  unite(제목, 본문, col = "text", sep = " ") %>% 
  mutate(text = str_squish(text))

s_tk <- s_df2 %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = "regex", drop = F) %>%
  count(word, sort = T)

s_tk <- 
s_tk %>% 
  filter(!word %in% c("한국수자원공사", "수자원공사", "환경부", "kwater")) %>%   filter(str_detect(word, "[:alpha:]+")) %>%
  filter(str_length(word) > 1) %>%
  slice_max(n, n = 15) %>% 
  mutate(word = reorder(word, n))

s_tk %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  labs(title = "수자원공사 단어 총빈도 분석")
```

```{r}
m_s_df <- m_df2 %>% 
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  count(word, sScore, sort = T) %>% 
  filter(str_length(word) > 1) %>% 
  mutate(word = reorder(word, n)) %>% 
  slice_head(n = 20)

m_s_df %>% 
  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +
    labs(title = "한국마사회 감성분석")

```
```{r}
s_s_df <- s_df2 %>% 
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  count(word, sScore, sort = T) %>% 
  filter(!word %in% c("피해")) %>%
  filter(str_length(word) > 1) %>% 
  mutate(word = reorder(word, n)) %>% 
  slice_head(n = 20)

# 피해단어가 압도적으로 많아 분석이 힘들어 피해 단어 삭제 

s_s_df %>% 
  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +
    labs(title = "한국수자원공사 감성분석")


```

```{r}
m_df2 %>% 
  unnest_tokens(word, text) %>% 
  left_join(senti_dic_df) %>% 
  mutate(sScore = ifelse(sScore >= 1, "긍정",
                         ifelse(sScore <= -1, "부정", "중립"))) 

m_df2 %>%   
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%
  mutate(label = ifelse(sScore > 0, "1", ifelse(sScore < 0, "0", "2"))) %>%
  filter(label != "중립") %>%
  count(word, emotion, label, sort = T) %>%
  filter(str_length(word) > 1) %>%
  group_by(label = ifelse(label > 0, "긍정", "부정")) %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = n,
             y = reorder(word, n), fill = label)) +
  geom_col(show.legend = F) +
  facet_wrap(~label, scale = "free") +
  labs(title = "한국 마사회 긍,부정어")
```

```{r}
s_df2 %>% 
  unnest_tokens(word, text) %>% 
  filter(!word %in% c("피해")) %>%
  left_join(senti_dic_df) %>% 
  mutate(sScore = ifelse(sScore >= 1, "긍정",
                         ifelse(sScore <= -1, "부정", "중립"))) 

s_df2 %>%   
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%
  mutate(label = ifelse(sScore > 0, "1", ifelse(sScore < 0, "0", "2"))) %>%
  filter(label != "중립") %>%
  count(word, emotion, label, sort = T) %>%
  filter(str_length(word) > 1) %>%
  filter(!word %in% c("피해","없다")) %>%
  group_by(label = ifelse(label > 0, "긍정", "부정")) %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = n,
             y = reorder(word, n), fill = label)) +
  geom_col(show.legend = F) +
  facet_wrap(~label, scale = "free") +
  labs(title = "한국 수자원공사 긍,부정어")
```




```{r}
weighted_log_odds_df1 <-
  bind_rows(m_tk, s_tk, .id = "party") %>% 
  bind_log_odds(set = party,
                feature = word, 
                n = n) %>% 
  arrange(-log_odds_weighted)
```

```{r}

library(gt)
library(dplyr)

m.s_df <- bind_cols(
  weighted_log_odds_df1 %>%   
  group_by(party = ifelse(party == 1, "한국마사회", "한국수자원공사")) %>% 
  arrange(party) %>% 
  select(-party) %>%
  head(15),
  
  weighted_log_odds_df1 %>%   
  group_by(party = ifelse(party == 1, "한국마사회", "한국수자원공사")) %>% 
  arrange(desc(party)) %>% 
  select(-party) %>%
  head(15) 
  ) 

m.s_df <- m.s_df[-c(1,5)]


m.s_df %>%
  gt() %>% tab_header(
  "상대 빈도 분석"
  ) %>% tab_spanner(
    label = "마사회 기준",
    columns = 1:3
  ) %>% tab_spanner(
    label = "수자원공사 기준",
    columns = 4:6
  ) %>% cols_label(
    word...2 = "명사",
    n...3 = "빈도",
    log_odds_weighted...4 = "가중상대빈도",
    word...6 = "명사",
    n...7 = "빈도",
    log_odds_weighted...8 = "가중상대빈도"
  ) %>% fmt_number(
    columns = starts_with("log"), 
    decimals = 2
  )
```
```{r}
s_ttk <- s_df2 %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = "regex", drop = F)

s_ttk <- 
s_ttk %>% 
   filter(!word %in% c("수자원공사", "한국수자원공사", "하굿둑", "박재현","수돗물","피해","kwater","방류")) %>%
  filter(str_detect(word, "[:alpha:]+"))

s_cdf <- s_ttk %>%
  group_by(ID) %>%
  summarise(text2 = str_flatten(word, " ")) %>%
  ungroup() %>% 
  inner_join(s_df2, by = "ID")

library(stm)
library(tm)

processed <- s_df2 %>% 
  textProcessor(
    documents = s_cdf$text2,
    metadata = .,
    wordLengths = c(2, Inf))

```

```{r}
out <- 
  prepDocuments(processed$documents,
                     processed$vocab,
                     processed$meta)

```

```{r}
docs <- out$documents
vocab <- out$vocab
meta <- out$meta

```

```{r}

topicN <- c(3, 10)
storage <- searchK(out$documents, out$vocab, K = topicN)
```


```{r}

s_stm_fit <-
 stm(
    documents = docs,
    vocab = vocab,
    K = 6,
    data = meta,
    max.em.its = 75,
    init.type = "Spectral",
    seed = 25,
    verbose = F
  ) 
```


```{r}
s_td_beta <- s_stm_fit %>% 
  tidy(matrix = 'beta') 

s_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 7) %>% 
  ungroup() %>% 
  mutate(topic = str_c("주제", topic))
 
   
s_topic_name <- tibble(topic = 1:5,
                     name = c("1. 수자원 산업",
                              "2. 수력에너지",
                              "3. 코로나 이후 활동",
                              "4.",
                              "5."))

s_td_beta <- s_stm_fit %>% tidy(matrix = 'beta') 
s_topic_name <- s_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 7) %>% 
  left_join(s_topic_name, by = "topic")

s_topic_name %>% 
  ggplot(aes(x = beta, 
             y = reorder_within(term, beta, name),  
             fill = name)) +
  geom_col(show.legend = F) +
  facet_wrap(~name, scales = "free") +
  scale_y_reordered() +                             
  labs(x = expression("단어 확률분포: "~beta), y = NULL,
       title = "수자원 주제별 단어 확률 분포") +
  theme(plot.title = element_text(size = 20))


```


```{r}
s_td_gamma <- s_stm_fit %>% tidy(matrix = "gamma") 
s_top_terms <- 
s_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 5) %>% 
  select(topic, term) %>% 
  summarise(terms = str_flatten(term, collapse = ", ")) 

s_gamma_terms <- 
s_td_gamma %>% 
  group_by(topic) %>% 
  summarise(gamma = mean(gamma)) %>% 
  left_join(s_top_terms, by = 'topic') %>% 
  left_join(s_topic_name, by = 'topic')
  
s_gamma_terms %>% 
  
  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +
  geom_col(show.legend = F) +
  geom_text(aes(label = round(gamma, 2)), 
            hjust = 1.15) +                
  geom_text(aes(label = terms), 
            hjust = -0.05) +              
  labs(x = expression("문서 확률분포"~(gamma)), y = NULL,
       title = "수자원 토픽 상위 주제어") +
  theme(plot.title = element_text(size = 20))
```


